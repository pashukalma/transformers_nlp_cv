{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, pickle, math, random\n",
        "from copy import deepcopy\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.__version__, torchvision.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b094VTFxJvNb",
        "outputId": "724bb81e-16f8-4505-bab9-f93bdf5fb4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.5.1+cu124', '0.20.1+cu124')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-Category Classification"
      ],
      "metadata": {
        "id": "6R3YqYQvyiZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' multi-category classification '''\n",
        "torch.manual_seed(42)\n",
        "transform=T.Compose(\n",
        "    [T.Resize((224, 224)),\n",
        "     T.ToTensor(),\n",
        "     T.Normalize(mean=[0.485,0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "train_set = torchvision.datasets.Country211(\n",
        "    root = '.', split='train', download=True, transform=transform ) #192\n",
        "test_set = torchvision.datasets.Country211(\n",
        "    root = '.', split='test', download=True, transform=transform ) #50\n",
        "validation_set = test_set = torchvision.datasets.Country211(\n",
        "    root = '.', split='valid', download=True, transform=transform ) #50\n",
        "\n",
        "batch_size = 64\n",
        "dataloader_train = DataLoader(train_set, batch_size, shuffle=True)\n",
        "dataloader_test = DataLoader(test_set, batch_size, shuffle=False)\n",
        "dataloader_validation = DataLoader(validation_set, batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "J67FeDXOOEtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStop:\n",
        "  def __init__(self, patience=10):\n",
        "    self.patience, self.steps, self.min_loss = patience, 0, float('inf')\n",
        "\n",
        "  def stop(self, validation_loss):\n",
        "    if validation_loss < self.min_loss:\n",
        "      self.min_loss, self.steps = validation_loss, 0\n",
        "    elif validation_loss >= self.min_loss:\n",
        "      self.steps +=1\n",
        "    if self.steps >= self.patience: return True\n",
        "    else: return False\n",
        "\n",
        "stopper = EarlyStop()"
      ],
      "metadata": {
        "id": "D-XsL_IWy7Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ = nn.Sequential(\n",
        "  nn.Linear(3*224*224, 256),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(256, 128),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(128, 64),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(64, 10)).to(device)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model_.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "jU6nQdoPy7Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' train the multi-category classifier '''\n",
        "def train_epoch():\n",
        "  training_loss = 0\n",
        "  for n, (images, labels) in enumerate(dataloader_train):\n",
        "    images = images.reshape(-1, 3*224*224).to(device)\n",
        "    labels = labels.reshape(-1,).to(device)\n",
        "    predictions = model_(images)\n",
        "    loss = loss_fn(predictions, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    training_loss += loss\n",
        "  return training_loss/n\n",
        "\n",
        "def validation_epoch():\n",
        "  validation_loss = 0\n",
        "  for n, (images, labels) in enumerate(dataloader_validation):\n",
        "    images = images.reshape(-1, 3*224*224).to(device)\n",
        "    labels = labels.reshape(-1, ).to(device)\n",
        "    predictions = model_(images)\n",
        "    loss = loss_fn(predictions, labels)\n",
        "    validation_loss +=loss\n",
        "  return validation_loss/n"
      ],
      "metadata": {
        "id": "RsjrGDdgy7et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 10):\n",
        "  training_loss = train_epoch()\n",
        "  validation_loss = validation_epoch()\n",
        "  print(f'at epoch {i}, \\\n",
        "        training loss {training_loss}, validation loss {validation_loss}')\n",
        "  if stopper.stop(validation_loss) == True:\n",
        "    break\n",
        "\n",
        "''' accuracy of multi category classifier '''\n",
        "results = []\n",
        "for images, labels in dataloader_test:\n",
        "  images = images.reshape(-1, 3*224*224).to(device)\n",
        "  labels = (labels).reshape(-1,).to(device)\n",
        "  predictions = model_(images)\n",
        "  predictions_ = torch.argmax(predictions, dim=1)\n",
        "  correct = (predictions_ == labels)\n",
        "  results.append(correct.detach().cpu().numpy().mean())\n",
        "\n",
        "accuracy = np.array(results).mean()\n",
        "accuracy"
      ],
      "metadata": {
        "id": "T93Dpot-1lZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CrossEntropyLoss combining LogSoftmax and NLLoss instead of  CrossEntropyLoss and SoftMax activation"
      ],
      "metadata": {
        "id": "QEE_dY3Q34gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model_.parameters(), lr=lr)\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "for i in range(1, 10):\n",
        "  training_loss = train_epoch()\n",
        "  validation_loss = validation_epoch()\n",
        "  print(f'at epoch {i}, training loss {training_loss}, validation loss {validation_loss}')\n",
        "  if stopper.stop(validation_loss) == True:\n",
        "    break\n",
        "\n",
        "''' accuracy of multi category classifier '''\n",
        "results = []\n",
        "for images, labels in dataloader_test:\n",
        "  images = images.reshape(-1, 3*224*224).to(device)\n",
        "  labels = (labels).reshape(-1,).to(device)\n",
        "  predictions = model_(images)\n",
        "  predictions_ = torch.argmax(predictions, dim=1)\n",
        "  correct = (predictions_ == labels)\n",
        "  results.append(correct.detach().cpu().numpy().mean())\n",
        "\n",
        "accuracy = np.array(results).mean()\n",
        "accuracy"
      ],
      "metadata": {
        "id": "D6EZVIcj3u8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}