{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Image Generation with GANs"
      ],
      "metadata": {
        "id": "8KT-RhW7-bfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, pickle, math, random\n",
        "from copy import deepcopy\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.__version__, torchvision.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hsoThBX-gEI",
        "outputId": "4e4f5b27-820f-4cbb-cdcc-ac14d3008992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.5.1+cu124', '0.20.1+cu124')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Reverse engineering steps in discriminator work, recap of 2D convolutional\n",
        "operator works on an image, 2D transposed convolutional operation, building\n",
        "and traiining GANs to generate color images '''"
      ],
      "metadata": {
        "id": "fvCCw7fQN_pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "transform=T.Compose(\n",
        "    [T.Resize((224, 224)),\n",
        "     T.ToTensor(),\n",
        "     T.Normalize(mean=[0.485,0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.Country211(\n",
        "    root = '.', split='train', download=True, transform=transform )\n",
        "test_set = torchvision.datasets.Country211(\n",
        "    root = '.', split='test', download=True, transform=transform )\n",
        "validation_set = test_set = torchvision.datasets.Country211(\n",
        "    root = '.', split='valid', download=True, transform=transform )\n",
        "\n",
        "batch_size = 64\n",
        "dataloader_train = DataLoader(train_set, batch_size, shuffle=True)\n",
        "dataloader_test = DataLoader(test_set, batch_size, shuffle=False)\n",
        "dataloader_validation = DataLoader(validation_set, batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "YAdq5A6O-gHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Discriminator Binary Classifier '''\n",
        "Discriminator = nn.Sequential(\n",
        "    nn.Linear(3*224*224, 5120),\n",
        "    nn.ReLU(), nn.Dropout(0.3),\n",
        "    nn.Linear(5120, 1024),\n",
        "    nn.ReLU(), nn.Dropout(0.3),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(), nn.Dropout(0.3),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(), nn.Dropout(0.3),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid()).to(device)\n",
        "\n",
        "Generator = nn.Sequential(\n",
        "    nn.Linear(100, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 5120),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5120, 3*224*224),\n",
        "    nn.Tanh()).to(device)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "lr = 0.0001\n",
        "optim_d = torch.optim.Adam(Discriminator.parameters(), lr=lr)\n",
        "optim_g = torch.optim.Adam(Generator.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "7gNlqelc_u0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize():\n",
        "  noise = torch.randn(85, 100).to(device)\n",
        "  samples_fake = Generator(noise).cpu().detach()\n",
        "  plt.figure(dpi=80, figsize=(10,5))\n",
        "  for i in range(4):\n",
        "    ax = plt.subplot(4, 8, i +1)\n",
        "    images = (samples_fake[i]).reshape(3, 224,224)\n",
        "    images  = images.numpy().transpose(1,2,0)\n",
        "    images = images *[0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
        "    plt.imshow(images)\n",
        "    plt.xticks([]) ; plt.yticks([])\n",
        "  plt.show()\n",
        "visualize()"
      ],
      "metadata": {
        "id": "2d4i_N-2_u6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scripted = torch.jit.script(Generator)\n",
        "os.makedirs('file-samples', exist_ok=True)\n",
        "scripted.save('file-samples/country211_gen.pt')\n",
        "new_generator = torch.jit.load('file-samples/country211_gen.pt', map_location=device)\n",
        "new_generator.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbqDviR9_u-x",
        "outputId": "5637fa1b-e2ea-4cbd-ae7c-e1aeb21414fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecursiveScriptModule(\n",
              "  original_name=Sequential\n",
              "  (0): RecursiveScriptModule(original_name=Linear)\n",
              "  (1): RecursiveScriptModule(original_name=ReLU)\n",
              "  (2): RecursiveScriptModule(original_name=Linear)\n",
              "  (3): RecursiveScriptModule(original_name=ReLU)\n",
              "  (4): RecursiveScriptModule(original_name=Linear)\n",
              "  (5): RecursiveScriptModule(original_name=ReLU)\n",
              "  (6): RecursiveScriptModule(original_name=Linear)\n",
              "  (7): RecursiveScriptModule(original_name=ReLU)\n",
              "  (8): RecursiveScriptModule(original_name=Linear)\n",
              "  (9): RecursiveScriptModule(original_name=Tanh)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device='cpu'"
      ],
      "metadata": {
        "id": "ieBqElQfUldi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator_onreal(samples_real):\n",
        "  r_ = samples_real.reshape(-1, 3*224*224).to(device)\n",
        "  out_ = Discriminator(r_)\n",
        "  labels_ = torch.ones((r_.shape[0], 1)).to(device)\n",
        "  loss_discriminator = loss_fn(out_, labels_)\n",
        "  optim_d.zero_grad()\n",
        "  loss_discriminator.backward()\n",
        "  optim_d.step()\n",
        "  return loss_discriminator\n",
        "\n",
        "def train_discriminator_onfake():\n",
        "  noise = torch.randn((batch_size, 100)).to(device)\n",
        "  generated_data = Generator(noise)\n",
        "  predictions = Discriminator(generated_data)\n",
        "  loss_discriminator = loss_fn(predictions, labels_fake)\n",
        "  optim_d.zero_grad()\n",
        "  loss_discriminator.backward()\n",
        "  optim_d.step()\n",
        "  return loss_discriminator\n",
        "\n",
        "def train_generator():\n",
        "  noise = torch.randn((batch_size, 100)).to(device)\n",
        "  generated_data  = Generator(noise)\n",
        "  predictions = Discriminator(generated_data)\n",
        "  loss_generator = loss_fn(predictions, labels_real)\n",
        "  optim_g.zero_grad()\n",
        "  loss_generator.backward()\n",
        "  optim_g.step()\n",
        "  return loss_generator\n",
        "\n",
        "labels_real = torch.ones((batch_size, 1)).to(device)\n",
        "labels_fake = torch.ones((batch_size, 1)).to(device)\n",
        "\n",
        "for i in range(2):\n",
        "  gloss, dloss = 0, 0\n",
        "  for n, (real_samples, _ ) in enumerate(dataloader_train):\n",
        "    loss_discriminator = train_discriminator_onreal(real_samples)\n",
        "    dloss += loss_discriminator\n",
        "    loss_discriminator = train_discriminator_onfake()\n",
        "    dloss += loss_discriminator\n",
        "    loss_generator = train_generator()\n",
        "    gloss += loss_generator\n",
        "  gloss /= n\n",
        "  dloss /= n\n",
        "  if i % 10 ==9:\n",
        "    print(f'at epoch {i+1}, dloss {dloss}, gloss {gloss}')\n",
        "    visualize()"
      ],
      "metadata": {
        "id": "9Axcm6fj_vCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.randn(batch_size, 100).to(device)\n",
        "samples_fake = Generator(noise).cpu().detach()\n",
        "plt.figure(dpi=80, figsize=(10,5))\n",
        "\n",
        "for i in range(4):\n",
        "    ax = plt.subplot(4, 8, i +1)\n",
        "    images = (samples_fake[i]).reshape(3, 224,224)\n",
        "    images  = images.numpy().transpose(1,2,0)\n",
        "    images = images *[0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
        "    plt.imshow(images)\n",
        "    plt.xticks([]) ; plt.yticks([])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqdxzqEagju1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "id": "9UqFX4o2EYee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}